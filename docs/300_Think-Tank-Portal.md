# 300: Think Tank Intelligence Portal

This document details the architecture and usage of the **Think Tank Intelligence Portal**, a lightweight, high-performance web interface for browsing the intelligence generated by the pipeline.

## 1. Overview

The Portal serves as a "read-only" frontend for the AI Daily Digest. It allows users to:
*   View the "Morning Paper" digest in a browser.
*   Filter content by Semantic Anchor, Source Category, and Relevance.
*   Search the entire article archive (12,000+ items) instantly.

It is designed to be **serverless** and **local-first**, meaning it does not require a backend API to run. Instead, it runs entirely in the user's browser using static data files.

## 2. Technology Stack

The portal is built using the **Observable Framework**, a modern static site generator optimized for data dashboards.

*   **Frontend:** HTML/JS/Markdown (Observable Framework).
*   **Database Engine:** **DuckDB-WASM**. This is a version of DuckDB that runs inside the web browser. It allows us to execute SQL queries directly against data files without a server.
*   **Data Format:** **Parquet**. The backend pipeline exports data into highly compressed, columnar Parquet files. These are significantly smaller and faster to query than CSV or JSON.

## 3. Architecture & Data Flow

1.  **Backend Pipeline:** The Python pipeline runs its daily cycle (Ingestion -> Analysis -> Enrichment).
2.  **Data Export:** The `scripts/export_to_parquet.py` script runs at the end of the pipeline. It queries the PostgreSQL database and creates four optimized files:
    *   `morning_paper.parquet`: Data for the last 7 days (optimized for the dashboard).
    *   `archive.parquet`: The complete history of all articles (optimized for search).
    *   `sources.parquet`: Metadata about active sources.
    *   `anchors.parquet`: Metadata about semantic anchors.
3.  **Build/Deploy:** These parquet files are saved to `portal/src/data/`. When the portal is built (or served), DuckDB-WASM loads these files to power the interface.

## 4. Directory Structure

The portal code lives in the `portal/` directory:

```
portal/
├── src/
│   ├── data/              # Location of generated Parquet files
│   ├── index.md           # The "Morning Paper" dashboard page
│   ├── archive.md         # The Archive search page
│   ├── sources.md         # The Source Manifest page
│   └── theme.css          # Custom styling
├── observablehq.config.js # Framework config
├── package.json           # Node.js dependencies
└── package-lock.json      # Dependency lock file
```

## 5. Development & Deployment

### Prerequisites
*   Node.js (v18 or higher)
*   NPM

### Running Locally
To run the portal on your local machine:

```bash
cd portal
npm install       # Install dependencies (first time only)
npm start         # Start the local development server
```

The portal will be accessible at `http://localhost:3000`.

### Building for Production
To build the static site for deployment (e.g., to GitHub Pages):

```bash
cd portal
npm run build
```

This generates a `dist/` directory containing the full static website, ready to be hosted anywhere.

### Deployment Strategy
The portal is designed to be hosted on **GitHub Pages**. The build process simply needs to run `npm run build` and push the `dist/` folder to the appropriate branch/repository.
