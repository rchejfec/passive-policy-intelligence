"""
DSPy Utilities for Passive Policy Intelligence.

This module provides the HyDEGenerator class to synthesize messy input data
into a clean 'Hypothetical Document' (HyDE) representing a policy topic.
"""

import os
import logging
from typing import List, Optional

# Treat dspy as a required dependency for this module
import dspy

# Get a logger for this module
logger = logging.getLogger(__name__)


class SynthesizeAnchor(dspy.Signature):
    """Synthesizes a list of context snippets into a single, clean 'Hypothetical Document' (HyDE) that represents a policy topic."""

    topic: str = dspy.InputField(desc="The policy topic to synthesize.")
    context: str = dspy.InputField(
        desc="A list of context snippets (URLs, PDFs, snippets) related to the topic."
    )
    synthetic_article: str = dspy.OutputField(
        desc="A ~300 word summary written in the style of an authoritative think-tank report."
    )


class HyDEGenerator:
    """
    Generator that synthesizes messy input data into a clean 'Hypothetical Document' (HyDE).
    """

    def __init__(self, lm_backend: Optional[dspy.LM] = None):
        """
        Initialize the HyDEGenerator.

        Args:
            lm_backend: An optional dspy.LM backend. If not provided, it attempts to
                        configure the default LM using the OPENAI_API_KEY environment variable.
        """
        self.lm_backend = lm_backend

        if not self.lm_backend:
            api_key = os.environ.get("OPENAI_API_KEY")
            if api_key:
                try:
                    # Initialize OpenAI backend.
                    self.lm_backend = dspy.LM('openai/gpt-3.5-turbo', api_key=api_key)
                except Exception as e:
                    logger.warning(f"Failed to initialize default OpenAI backend: {e}")
            else:
                logger.warning("No dspy.LM backend provided and OPENAI_API_KEY not found.")

    def generate_hyde(self, context_list: List[str], topic_name: str) -> str:
        """
        Synthesize a list of context strings into a single HyDE document.

        Args:
            context_list: A list of strings representing the messy input data.
            topic_name: The name of the policy topic.

        Returns:
            A string containing the synthesized article or a concatenation of inputs as fallback.
        """
        # Fallback logic check
        use_fallback = False

        # Check if we have a backend to use (either self.lm_backend or global dspy.settings.lm)
        effective_lm = self.lm_backend
        if not effective_lm and not dspy.settings.lm:
            use_fallback = True

        if not use_fallback:
            try:
                # Use the configured backend in a context, or rely on global settings if self.lm_backend is None
                # We use dspy.context to avoid polluting global state
                context_manager = dspy.context(lm=self.lm_backend) if self.lm_backend else dspy.context()

                with context_manager:
                    # Instantiate the module
                    generate_anchor = dspy.Predict(SynthesizeAnchor)

                    # Join context list into a single string for the prompt
                    context_str = "\n---\n".join(context_list)

                    response = generate_anchor(topic=topic_name, context=context_str)
                    return response.synthetic_article
            except Exception as e:
                logger.error(f"DSPy generation failed: {e}")
                use_fallback = True

        # Fallback implementation
        logger.info("Using fallback concatenation.")
        concatenated = "\n".join(context_list)
        return concatenated[:3000]


if __name__ == "__main__":
    # Test Block to mock a generation
    # Configure logging for the test run
    logging.basicConfig(level=logging.INFO)
    print("Testing HyDEGenerator...")

    # Define a Mock LM for testing purposes
    class MockLM(dspy.LM):
        def __init__(self):
            super().__init__("mock")
            self.history = []

        def __call__(self, prompt=None, messages=None, **kwargs):
             # Mock the response structure expected by dspy.
             # Since dspy 3.0 often uses adapters that expect JSON-structured output for Signatures,
             # we return a JSON string matching the output field.
             return ['{"synthetic_article": "Title: Synthetic Report\\n\\nThis is a mocked synthetic article generated by the MockLM."}']

    # Context
    test_context = [
        "Snippet 1: The policy on renewable energy is shifting towards solar.",
        "Snippet 2: Government subsidies for coal are decreasing.",
        "Snippet 3: New wind farms approved in the north."
    ]
    test_topic = "Renewable Energy Transition"

    # 1. Test Fallback (No Backend)
    print("\n--- Testing Fallback (No Backend) ---")
    # Temporarily unset OPENAI_API_KEY to force fallback if it exists
    original_api_key = os.environ.get("OPENAI_API_KEY")
    if "OPENAI_API_KEY" in os.environ:
        del os.environ["OPENAI_API_KEY"]

    # Also ensure global dspy.settings.lm is unset or we account for it
    # But since we are running isolated, it should be None by default unless configured.
    # We can force it to None in context for test if needed, but dspy.context(lm=None) doesn't "unset" it,
    # it just sets it to None, which might fallback to global?
    # Actually dspy.settings.configure(lm=None) might clear it.

    try:
        gen_fallback = HyDEGenerator(lm_backend=None)
        result_fallback = gen_fallback.generate_hyde(test_context, test_topic)
        print(f"Result (Fallback): {result_fallback[:100]}...")
        if result_fallback.startswith("Snippet 1"):
            print("SUCCESS: Fallback logic works.")
        else:
            print("FAILURE: Fallback logic did not return concatenation.")
    finally:
        if original_api_key:
            os.environ["OPENAI_API_KEY"] = original_api_key

    # 2. Test Mock Backend
    print("\n--- Testing Mock Backend ---")
    mock_lm = MockLM()
    gen_mock = HyDEGenerator(lm_backend=mock_lm)

    result_mock = gen_mock.generate_hyde(test_context, test_topic)
    print(f"Result (Mock): {result_mock}")

    if "mocked synthetic article" in result_mock:
        print("SUCCESS: Mock generation works.")
    else:
        # If it failed and went to fallback
        print("WARNING: Mock generation might have failed or fallen back.")
